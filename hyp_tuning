# hyperparameter tuning

import optuna
from sklearn.metrics import log_loss

def objective(trial):
    params = {
        'objective': 'regression',
        'metric' : {'binary_logloss'},
        'num_leaves': trial.suggest_int('num_leaves', 32, 128),
        'learning_rate': 0.01,
        'max_bin': trial.suggest_int('max_bin', 255, 500)
    }
    
    lgb_train = lgb.Dataset(X_train, y_train)
    
    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)
    
    model = lgb.train(params, lgb_train,
                     valid_sets=[lgb_train, lgb_eval],
                     verbose_eval=10,
                     num_boost_round=1000,
                     early_stopping_rounds=10)
    
    y_pred_valid = model.predict(X_test,
                                num_iteration=model.best_iteration)
    score = log_loss(y_test, y_pred_valid)
    return score

study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=0))
study.optimize(objective, n_trials=40)
study.best_params
